import streamlit as st
import pandas as pd
from jinja2 import Environment, FileSystemLoader
from weasyprint import HTML, CSS
from datetime import datetime
import streamlit.components.v1 as components
from openai import OpenAI
import json
import os
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import io
import re
import PyPDF2
from pptx import Presentation
import openpyxl

# --- í•™ìŠµëœ ë¬¸ì„œ ê´€ë¦¬ ---
learned_documents = {}
learning_status = {"manual": False, "samples": False}

def load_learned_documents():
    """í•™ìŠµëœ ë¬¸ì„œ ë‚´ìš©ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global learned_documents, learning_status
    try:
        if os.path.exists('learned_documents.json'):
            with open('learned_documents.json', 'r', encoding='utf-8') as f:
                learned_documents = json.load(f)
                learning_status = {
                    "manual": learned_documents.get('manual', {}).get('content', '') != '',
                    "samples": learned_documents.get('samples', {}).get('content', '') != ''
                }
                return True
    except Exception as e:
        st.error(f"í•™ìŠµëœ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    return False

def get_learning_enhanced_prompt(base_prompt, doc_type):
    """í•™ìŠµëœ ë‚´ìš©ì´ í¬í•¨ëœ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not learned_documents:
        return base_prompt
    
    enhancement = "\n\n[í•™ìŠµëœ ë¬¸ì„œ ê°€ì´ë“œë¼ì¸]:\n"
    
    if learning_status.get("manual") and learned_documents.get('manual', {}).get('content'):
        enhancement += "\nğŸ“‹ ë¬¸ì„œì‘ì„± ê°€ì´ë“œë¼ì¸:\n"
        enhancement += learned_documents['manual']['content']
    
    if learning_status.get("samples") and learned_documents.get('samples', {}).get('content'):
        enhancement += "\nğŸ“ í’ˆì˜ì„œ ì‘ì„± íŒ¨í„´:\n"
        enhancement += learned_documents['samples']['content']
    
    enhancement += "\n\nìœ„ ê°€ì´ë“œë¼ì¸ê³¼ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ ë”ìš± ì „ë¬¸ì ì´ê³  ì™„ì„±ë„ ë†’ì€ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
    
    return base_prompt + enhancement

def reset_learning_data():
    """í•™ìŠµ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global learned_documents, learning_status
    try:
        if os.path.exists('learned_documents.json'):
            os.remove('learned_documents.json')
        learned_documents = {}
        learning_status = {"manual": False, "samples": False}
        return True
    except Exception as e:
        st.sidebar.error(f"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

# ì•± ì‹œì‘ ì‹œ í•™ìŠµëœ ë¬¸ì„œ ë¡œë“œ
load_learned_documents()

# --- AI ì„¤ì • (OpenAI GPT-4o mini ì‚¬ìš©) ---
client = None
openai_available = False

try:
    if "OPENAI_API_KEY" in st.secrets:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        openai_available = True
    else:
        st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
except Exception as e:
    st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.warning("AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

def get_ai_response(system_prompt, user_prompt):
    """OpenAI APIë¥¼ í˜¸ì¶œí•˜ëŠ” ë²”ìš© í•¨ìˆ˜"""
    if not openai_available or client is None:
        st.error("âš ï¸ OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    if not system_prompt or not user_prompt:
        st.error("í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None
        
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=3000,
            timeout=30
        )
        
        if not response.choices or not response.choices[0].message.content:
            st.error("AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
            
        content = response.choices[0].message.content.strip()
        if not content:
            st.error("AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
            
        return json.loads(content)
        
    except json.JSONDecodeError as e:
        st.error(f"AI ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}")
        return None
    except Exception as e:
        error_msg = str(e)
        if "rate limit" in error_msg.lower():
            st.error("âš ï¸ API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        elif "timeout" in error_msg.lower():
            st.error("âš ï¸ AI ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        elif "insufficient_quota" in error_msg.lower():
            st.error("âš ï¸ OpenAI API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê³„ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.error(f"AI ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}")
        return None

def analyze_keywords(keywords, doc_type):
    """í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    analysis_prompt = f"ì‚¬ìš©ìê°€ '{doc_type}' ì‘ì„±ì„ ìœ„í•´ ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤: '{keywords}'. 6W3H ì›ì¹™ì— ë”°ë¼ ì™„ì„±ë„ ë†’ì€ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê¸°ì— ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´, ê°€ì¥ ì¤‘ìš”í•œ ì§ˆë¬¸ 2-3ê°œë¥¼ `{{\"status\": \"incomplete\", \"questions\": [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\"]}}` í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ê³ , ì¶©ë¶„í•˜ë‹¤ë©´ `{{\"status\": \"complete\"}}` ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."
    base_system_prompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ì‘ì„±ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì§ˆë¬¸í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."
    
    # í•™ìŠµëœ ë‚´ìš©ìœ¼ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°•í™”
    enhanced_system_prompt = get_learning_enhanced_prompt(base_system_prompt, doc_type)
    
    return get_ai_response(enhanced_system_prompt, analysis_prompt)

def generate_ai_draft(doc_type, context_keywords, file_context=""):
    """ìµœì¢… í‚¤ì›Œë“œì™€ íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ AI ì´ˆì•ˆì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    user_prompt = f"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{doc_type}' ì´ˆì•ˆì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n[í•µì‹¬ í‚¤ì›Œë“œ]: {context_keywords}\n\n[ì²¨ë¶€ íŒŒì¼ ë‚´ìš©]:\n{file_context}"
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ í•™ìŠµëœ ë‚´ìš©ìœ¼ë¡œ ê°•í™”
    base_prompts = {
        "í’ˆì˜ì„œ": "ë‹¹ì‹ ì€ í•œêµ­ì˜ 'ì£¼ì‹íšŒì‚¬ ëª¬ì‰˜ì½”ë¦¬ì•„' ì†Œì†ì˜ ìœ ëŠ¥í•œ ì‚¬ì›ì…ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì œê³µí•˜ëŠ” ê·œì¹™ê³¼ ì˜ˆì‹œë¥¼ ì™„ë²½í•˜ê²Œ ìˆ™ì§€í•˜ê³ , ì‚¬ìš©ìì˜ í‚¤ì›Œë“œì™€ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ í’ˆì˜ì„œ ì´ˆì•ˆ ì „ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë¬¸ì¥ì˜ ì¢…ê²°ì–´ë¯¸ëŠ” `...í•¨.`, `...ìš”ì²­í•¨.`ê³¼ ê°™ì´ ëª…ì‚¬í˜•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì¢…ê²°í•´ì•¼ í•©ë‹ˆë‹¤. ë³¸ë¬¸ í•­ëª© êµ¬ë¶„ ì‹œ ë°˜ë“œì‹œ `1.`, `  1)`, `    (1)` ì˜ ìœ„ê³„ì§ˆì„œë¥¼ ì¤€ìˆ˜í•˜ê³ , ê° ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œ í›„ì—ëŠ” ì¤„ë°”ê¿ˆì„ í•´ì£¼ì„¸ìš”. `#` ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ìƒì„¸ ë‚´ìš©ì€ 'body'(í…ìŠ¤íŠ¸ ì„¤ëª…)ì™€ 'items'(í‘œ ë°ì´í„°) ëª¨ë‘ í¬í•¨í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”. í…ìŠ¤íŠ¸ë¡œ ë°°ê²½ê³¼ ëª©ì ì„ ì„¤ëª…í•˜ê³ , í‘œë¡œ êµ¬ì²´ì ì¸ í•­ëª©ê³¼ ìˆ˜ì¹˜ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”. ì‘ë‹µì€ `title`, `purpose`, `body`, `items`, `remarks` ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "ê³µì§€ë¬¸": "ë‹¹ì‹ ì€ í•œêµ­ ê¸°ì—…ì˜ ì‚¬ë‚´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë‹´ë‹¹ìì…ë‹ˆë‹¤. í‚¤ì›Œë“œì™€ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ì‚¬ë‚´ ê³µì§€ë¬¸' ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. 'details' í•„ë“œì—ëŠ” `1.`, `  1)`, `    (1)` ì˜ ìœ„ê³„ì§ˆì„œë¥¼ ì¤€ìˆ˜í•˜ëŠ” ë²ˆí˜¸ ë§¤ê¸°ê¸°ë¥¼ ì‚¬ìš©í•˜ê³ , ê° ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œ í›„ì—ëŠ” ì¤„ë°”ê¿ˆì„ í•´ì£¼ì„¸ìš”. detailsëŠ” í•˜ë‚˜ì˜ ì—°ì†ëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´ì´ì–´ì•¼ í•˜ë©°, JSON ê°ì²´ê°€ ì•„ë‹Œ ì¼ë°˜ ë¬¸ìì—´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì‘ë‹µì€ 'title', 'target', 'summary', 'details', 'contact' keyë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "ê³µë¬¸": "ë‹¹ì‹ ì€ ëŒ€ì™¸ ë¬¸ì„œë¥¼ ë‹´ë‹¹í•˜ëŠ” ì´ë¬´íŒ€ ì§ì›ì…ë‹ˆë‹¤. í‚¤ì›Œë“œì™€ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê²©ì‹ì— ë§ëŠ” 'ê³µë¬¸' ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. ë³¸ë¬¸ ì‘ì„± ì‹œ `1.`, `  1)`, `    (1)` ì˜ ìœ„ê³„ì§ˆì„œë¥¼ ì¤€ìˆ˜í•˜ê³ , ê° ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œ í›„ì—ëŠ” ì¤„ë°”ê¿ˆì„ í•´ì£¼ì„¸ìš”. ì‘ë‹µì€ 'sender_org', 'receiver', 'cc', 'title', 'body', 'sender_name' keyë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
        "ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í‚¤ì›Œë“œì™€ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼' ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. ë³¸ë¬¸ ì‘ì„± ì‹œ `1.`, `  1)`, `    (1)` ì˜ ìœ„ê³„ì§ˆì„œë¥¼ ì¤€ìˆ˜í•˜ê³ , ê° ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œ í›„ì—ëŠ” ì¤„ë°”ê¿ˆì„ í•´ì£¼ì„¸ìš”. ì‘ë‹µì€ `subject`, `body`, `closing` keyë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. `closing`ì—ëŠ” íšŒì‚¬ëª…, ì—°ë½ì²˜, ì´ë©”ì¼ ì£¼ì†Œ ë“±ì˜ ì„œëª… ì •ë³´ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë‹¨ìˆœíˆ ì¸ì‚¬ë§ì´ë‚˜ ë§ˆë¬´ë¦¬ ë¬¸êµ¬ë§Œ í¬í•¨í•˜ì„¸ìš”."
    }
    
    # í•™ìŠµëœ ë‚´ìš©ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ê°•í™”
    enhanced_system_prompt = get_learning_enhanced_prompt(base_prompts[doc_type], doc_type)
    
    prompts = {
        "í’ˆì˜ì„œ": {"system": enhanced_system_prompt, "user": user_prompt},
        "ê³µì§€ë¬¸": {"system": enhanced_system_prompt, "user": user_prompt},
        "ê³µë¬¸": {"system": enhanced_system_prompt, "user": user_prompt},
        "ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼": {"system": enhanced_system_prompt, "user": user_prompt}
    }
    return get_ai_response(prompts[doc_type]["system"], prompts[doc_type]["user"])

# --- íŒŒì¼ ì½ê¸° ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ---
def read_uploaded_file(uploaded_file):
    if not uploaded_file:
        return ""
        
    # íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
    max_file_size = 10 * 1024 * 1024  # 10MB
    if hasattr(uploaded_file, 'size') and uploaded_file.size > max_file_size:
        st.error(f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. 10MB ì´í•˜ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return ""
    
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == "pdf":
            try:
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                if len(pdf_reader.pages) > 50:
                    st.warning("PDF íŒŒì¼ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì²˜ìŒ 50í˜ì´ì§€ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                
                text = ""
                for i, page in enumerate(pdf_reader.pages[:50]):
                    page_text = page.extract_text() or ""
                    text += page_text
                    
                if not text.strip():
                    st.warning("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return text
            except Exception as e:
                st.error(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return ""
                
        elif file_extension == "docx":
            try:
                doc = Document(uploaded_file)
                text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
                if not text.strip():
                    st.warning("Word ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return text
            except Exception as e:
                st.error(f"Word íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return ""
                
        elif file_extension == "pptx":
            try:
                prs = Presentation(uploaded_file)
                text = ""
                for slide in prs.slides:
                    for shape in slide.shapes:
                        if hasattr(shape, "text") and shape.text.strip(): 
                            text += shape.text + "\n"
                if not text.strip():
                    st.warning("PowerPointì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return text
            except Exception as e:
                st.error(f"PowerPoint íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return ""
                
        elif file_extension in ['xlsx', 'xls']:
            try:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
                if df.empty:
                    st.warning("Excel íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    return ""
                return df.head(100).to_string()  # ì²« 100í–‰ë§Œ ì²˜ë¦¬
            except Exception as e:
                st.error(f"Excel íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return ""
                
        elif file_extension == "txt":
            try:
                content = uploaded_file.getvalue()
                text = content.decode("utf-8")
                if not text.strip():
                    st.warning("í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return text
            except UnicodeDecodeError:
                try:
                    text = content.decode("euc-kr")
                    return text
                except UnicodeDecodeError:
                    st.error("í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return ""
            except Exception as e:
                st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return ""
        else:
            st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: .{file_extension}")
            return ""
            
    except Exception as e:
        st.error(f"'{uploaded_file.name}' íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return ""

def renumber_text(text):
    lines = text.split('\n')
    new_lines = []; counters = [0, 0, 0]
    for line in lines:
        stripped_line = line.lstrip()
        indentation = len(line) - len(stripped_line)
        match = re.match(r'^(\d+\.|\d+\)|\(\d+\)|\-|\*)\s+', stripped_line)
        if match:
            level = indentation // 2
            if level > 2: level = 2
            for i in range(level + 1, len(counters)): counters[i] = 0
            counters[level] += 1
            if level == 0: new_prefix = f"{counters[level]}. "
            elif level == 1: new_prefix = f"{'  ' * level}{counters[level]}) "
            else: new_prefix = f"{'  ' * level}({counters[level]}) "
            content_part = stripped_line[len(match.group(1)):].lstrip()
            new_lines.append("  " * level + new_prefix + content_part)
        else:
            new_lines.append(line)
    return "\n".join(new_lines)

def clean_text(text):
    if not isinstance(text, str): return ""
    # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
    processed_text = re.sub(r'^\s*#+\s*', '', text, flags=re.MULTILINE)
    # ë§ˆì¹¨í‘œ ë’¤ì— ì¤„ë°”ê¿ˆì´ ì—†ìœ¼ë©´ ì¶”ê°€ (ë‹¨, ìˆ«ì ë’¤ì˜ ë§ˆì¹¨í‘œëŠ” ì œì™¸)
    processed_text = re.sub(r'\.(?!\s*\n)(?!\s*$)(?!\d)', '.\n', processed_text)
    # ë²ˆí˜¸ ë§¤ê¸°ê¸° ì •ë¦¬
    processed_text = renumber_text(processed_text)
    return processed_text

def text_to_html(text): 
    """í…ìŠ¤íŠ¸ë¥¼ HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(text, dict):
        # JSON ê°ì²´ í˜•íƒœë¡œ ëœ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        formatted_text = ""
        for key, value in text.items():
            if key.strip() in ['1.', '2.', '3.', '4.', '5.']:
                formatted_text += f"{key} {value}\n"
            elif key.strip().endswith(')') and key.strip().replace(')', '').strip().isdigit():
                formatted_text += f"  {key} {value}\n"
            elif key.strip().startswith('(') and key.strip().endswith(')'):
                formatted_text += f"    {key} {value}\n"
            else:
                formatted_text += f"{key} {value}\n"
        text = formatted_text
    
    return clean_text(text).replace('\n', '<br>')

def validate_input_length(text, min_length=0, max_length=10000, field_name="ì…ë ¥"):
    """ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ ìœ íš¨ì„± ê²€ì‚¬"""
    if not text:
        return f"{field_name}ì„(ë¥¼) ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    text_length = len(text.strip())
    if text_length < min_length:
        return f"{field_name}ì´(ê°€) ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ {min_length}ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”."
    elif text_length > max_length:
        return f"{field_name}ì´(ê°€) ë„ˆë¬´ ê¹ë‹ˆë‹¤. {max_length}ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    return None

def show_progress_with_status(steps, delay=0.5):
    """ì§„í–‰ë¥ ê³¼ ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    import time
    for i, step_message in enumerate(steps):
        progress = (i + 1) / len(steps)
        progress_bar.progress(progress)
        status_text.text(step_message)
        time.sleep(delay)
    
    return progress_bar, status_text

def validate_document_fields(doc_type, data):
    """ë¬¸ì„œ ìœ í˜•ë³„ í•„ë“œ ìœ íš¨ì„± ê²€ì‚¬"""
    errors = []
    
    if doc_type == 'í’ˆì˜ì„œ':
        if not data.get("title") or len(data["title"].strip()) < 5:
            errors.append("ì œëª©ì„ 5ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        if not data.get("purpose") or len(data["purpose"].strip()) < 20:
            errors.append("ëª©ì ì„ 20ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif doc_type == 'ê³µì§€ë¬¸':
        if not data.get("title") or len(data["title"].strip()) < 5:
            errors.append("ì œëª©ì„ 5ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        if not data.get("target") or len(data["target"].strip()) < 2:
            errors.append("ëŒ€ìƒì„ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif doc_type == 'ê³µë¬¸':
        if not data.get("sender_org") or len(data["sender_org"].strip()) < 3:
            errors.append("ë°œì‹  ê¸°ê´€ëª…ì„ 3ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        if not data.get("receiver") or len(data["receiver"].strip()) < 3:
            errors.append("ìˆ˜ì‹ ì„ 3ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif doc_type == 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼':
        if not data.get("subject") or len(data["subject"].strip()) < 5:
            errors.append("ì œëª©ì„ 5ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        if not data.get("body") or len(data["body"].strip()) < 10:
            errors.append("ë³¸ë¬¸ì„ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    return errors

def generate_pdf(html_content):
    font_css = CSS(string="@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap'); body { font-family: 'Noto Sans KR', sans-serif; }")
    return HTML(string=html_content).write_pdf(stylesheets=[font_css])

def generate_docx(draft_data, doc_type, signature_data={}):
    doc = Document()
    style = doc.styles['Normal']; style.font.name = 'ë§‘ì€ ê³ ë”•'; style.font.size = Pt(11)
    if doc_type == 'í’ˆì˜ì„œ':
        h = doc.add_heading(draft_data.get('title', 'ì œëª© ì—†ìŒ'), level=1); h.alignment = WD_ALIGN_PARAGRAPH.CENTER
        doc.add_paragraph(clean_text(draft_data.get('purpose', '')))
        doc.add_paragraph("- ì•„ ë˜ -").alignment = WD_ALIGN_PARAGRAPH.CENTER
        doc.add_heading("1. ìƒì„¸ ë‚´ì—­", level=2)
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© ë¨¼ì € ì¶”ê°€
        if "body" in draft_data and draft_data.get("body"):
            doc.add_paragraph(clean_text(draft_data.get('body', '')))
            if "items" in draft_data and draft_data["items"]:
                doc.add_paragraph("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        # í‘œ ë°ì´í„° ì¶”ê°€
        if "items" in draft_data and draft_data["items"]:
            df = pd.DataFrame(draft_data["items"])
            if not df.empty:
                table = doc.add_table(rows=1, cols=len(df.columns), style='Table Grid')
                hdr_cells = table.rows[0].cells
                for i, col_name in enumerate(df.columns): 
                    hdr_cells[i].text = col_name
                for _, row in df.iterrows():
                    row_cells = table.add_row().cells
                    for i, col_name in enumerate(df.columns): 
                        row_cells[i].text = str(row[col_name])
        doc.add_heading("2. ë¹„ê³ ", level=2)
        doc.add_paragraph(clean_text(draft_data.get('remarks', '')))
        p_end = doc.add_paragraph("ë."); p_end.alignment = WD_ALIGN_PARAGRAPH.RIGHT
    elif doc_type == 'ê³µì§€ë¬¸':
        h = doc.add_heading(draft_data.get('title', 'ì œëª© ì—†ìŒ'), level=1); h.alignment = WD_ALIGN_PARAGRAPH.CENTER
        doc.add_paragraph(f"ëŒ€ìƒ: {draft_data.get('target', '')}")
        doc.add_paragraph(f"í•µì‹¬ ìš”ì•½: {draft_data.get('summary', '')}")
        doc.add_paragraph("-" * 30)
        doc.add_paragraph(clean_text(draft_data.get('details', '')))
        doc.add_paragraph(f"\në¬¸ì˜: {draft_data.get('contact', '')}")
    elif doc_type == 'ê³µë¬¸':
        h = doc.add_heading("ê³µ ì‹ ë¬¸ ì„œ", level=1); h.alignment = WD_ALIGN_PARAGRAPH.CENTER
        doc.add_paragraph(f"ë°œì‹ : {draft_data.get('sender_org', '')}")
        doc.add_paragraph(f"ìˆ˜ì‹ : {draft_data.get('receiver', '')}")
        doc.add_paragraph(f"ì°¸ì¡°: {draft_data.get('cc', '')}")
        doc.add_paragraph("-" * 30)
        doc.add_paragraph(f"ì œëª©: {draft_data.get('title', '')}")
        doc.add_paragraph(clean_text(draft_data.get('body', '')))
        p = doc.add_paragraph(f"\n\n{draft_data.get('sender_name', '')}"); p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    elif doc_type == 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼':
        doc.add_paragraph(f"ë°›ëŠ” ì‚¬ëŒ: {signature_data.get('recipient_name', '')} {signature_data.get('recipient_title', '')}")
        doc.add_paragraph(f"ì°¸ì¡°: {draft_data.get('cc', '')}")
        doc.add_paragraph(f"ì œëª©: {draft_data.get('subject', '')}")
        doc.add_paragraph("-" * 30)
        doc.add_paragraph(f"ì•ˆë…•í•˜ì„¸ìš”, {signature_data.get('recipient_name', '')} {signature_data.get('recipient_title', '')}ë‹˜.")
        doc.add_paragraph(f"{signature_data.get('signature_name', '')} {signature_data.get('signature_title', '')}ì…ë‹ˆë‹¤.")
        doc.add_paragraph() 
        doc.add_paragraph(clean_text(draft_data.get('body', '')))
        doc.add_paragraph(clean_text(draft_data.get('closing', '')))
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

st.set_page_config(page_title="ë¬¸ì„œ ì‘ì„± ë„ìš°ë¯¸", layout="wide")
env = Environment(loader=FileSystemLoader('.'))
def load_template(template_name): return env.get_template(template_name)
def generate_html(template, context): return template.render(context)

def clear_all_state():
    """ë¬¸ì„œ ìœ í˜• ë³€ê²½ ì‹œ ê´€ë ¨ ìƒíƒœë§Œ ì´ˆê¸°í™”"""
    keys_to_keep = ['doc_type_selector']
    keys_to_remove = [key for key in st.session_state.keys() if key not in keys_to_keep]
    for key in keys_to_remove:
        del st.session_state[key]

st.sidebar.title("ğŸ“‘ ë¬¸ì„œ ì¢…ë¥˜ ì„ íƒ")
# ì´ì „ ë¬¸ì„œ íƒ€ì… ì €ì¥
if 'previous_doc_type' not in st.session_state:
    st.session_state.previous_doc_type = None

doc_type = st.sidebar.radio("ì‘ì„±í•  ë¬¸ì„œì˜ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.", ('í’ˆì˜ì„œ', 'ê³µì§€ë¬¸', 'ê³µë¬¸', 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼'), key="doc_type_selector")

# --- ì„¤ì • ì„¹ì…˜ ---
st.sidebar.divider()
st.sidebar.title("âš™ï¸ ì„¤ì •")

# í•™ìŠµ ìƒíƒœ í‘œì‹œ
if learning_status["manual"] or learning_status["samples"]:
    st.sidebar.success("ğŸ“š í•™ìŠµ ì™„ë£Œ!")
    
    # ìƒì„¸ ìƒíƒœ í‘œì‹œ
    if learning_status["manual"]:
        manual_info = learned_documents.get('manual', {})
        source = manual_info.get('source', 'unknown')
        if source == 'pdf_extracted':
            st.sidebar.text("âœ… ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼ (PDF ì¶”ì¶œ)")
        else:
            st.sidebar.text("âš ï¸ ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼ (ê¸°ë³¸ê°’)")
    
    if learning_status["samples"]:
        samples_info = learned_documents.get('samples', {})
        source = samples_info.get('source', 'unknown')
        if source == 'pdf_extracted':
            st.sidebar.text("âœ… í’ˆì˜ì„œ ëª¨ìŒ (PDF ì¶”ì¶œ)")
        else:
            st.sidebar.text("âš ï¸ í’ˆì˜ì„œ ëª¨ìŒ (ê¸°ë³¸ê°’)")
    
    # í•™ìŠµ í†µê³„ í‘œì‹œ
    summary = learned_documents.get('summary', {})
    if summary:
        total_length = summary.get('total_content_length', 0)
        st.sidebar.caption(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {total_length:,}ì")
    
    learned_at = learned_documents.get('learned_at', 'ì•Œ ìˆ˜ ì—†ìŒ')
    st.sidebar.caption(f"í•™ìŠµ ì¼ì‹œ: {learned_at}")
else:
    st.sidebar.warning("ğŸ“– ì•„ì§ í•™ìŠµë˜ì§€ ì•ŠìŒ")

# í•™ìŠµ ì‹¤í–‰ ë²„íŠ¼
if st.sidebar.button("ğŸ“š PDF ë¬¸ì„œ í•™ìŠµí•˜ê¸°", use_container_width=True):
    try:
        with st.spinner("PDF ë¬¸ì„œë¥¼ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
            # ì‹¤ì œ PDF íŒŒì¼ ì½ê¸°
            from datetime import datetime
            
            def read_pdf_file(filename):
                """PDF íŒŒì¼ì„ ì½ì–´ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
                try:
                    if not os.path.exists(filename):
                        return f"íŒŒì¼ '{filename}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    
                    with open(filename, 'rb') as file:
                        pdf_reader = PyPDF2.PdfReader(file)
                        text = ""
                        for page in pdf_reader.pages:
                            page_text = page.extract_text()
                            if page_text:
                                text += page_text + "\n"
                        
                        if not text.strip():
                            return f"PDF '{filename}'ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        
                        return text.strip()
                        
                except Exception as e:
                    return f"PDF '{filename}' ì½ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}"
            
            # ì‹¤ì œ PDF íŒŒì¼ë“¤ ì½ê¸°
            st.info("ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼.PDF ì½ëŠ” ì¤‘...")
            manual_content = read_pdf_file('ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼.PDF')
            
            st.info("ìœ ì œìš± í’ˆì˜ì„œ ëª¨ìŒ.pdf ì½ëŠ” ì¤‘...")
            samples_content = read_pdf_file('ìœ ì œìš± í’ˆì˜ì„œ ëª¨ìŒ.pdf')
            
            # ì½ê¸° ê²°ê³¼ í™•ì¸
            manual_success = not manual_content.startswith("íŒŒì¼") and not manual_content.startswith("PDF")
            samples_success = not samples_content.startswith("íŒŒì¼") and not samples_content.startswith("PDF")
            
            if not manual_success:
                st.warning(f"âš ï¸ ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼.PDF: {manual_content}")
                manual_content = "PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            if not samples_success:
                st.warning(f"âš ï¸ ìœ ì œìš± í’ˆì˜ì„œ ëª¨ìŒ.pdf: {samples_content}")
                samples_content = "PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ìƒ˜í”Œ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            learned_content = {
                'manual': {
                    'filename': 'ë¬¸ì„œì‘ì„±ë©”ë‰´ì–¼.PDF',
                    'content': manual_content,
                    'source': 'pdf_extracted' if manual_success else 'fallback_guidelines',
                    'length': len(manual_content),
                    'success': manual_success
                },
                'samples': {
                    'filename': 'ìœ ì œìš± í’ˆì˜ì„œ ëª¨ìŒ.pdf', 
                    'content': samples_content,
                    'source': 'pdf_extracted' if samples_success else 'fallback_patterns',
                    'length': len(samples_content),
                    'success': samples_success
                },
                'learned_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'status': 'learned',
                'summary': {
                    'manual_extracted': manual_success,
                    'samples_extracted': samples_success,
                    'total_content_length': len(manual_content) + len(samples_content)
                }
            }
            
            # learned_documents.json íŒŒì¼ë¡œ ì €ì¥
            with open('learned_documents.json', 'w', encoding='utf-8') as f:
                json.dump(learned_content, f, ensure_ascii=False, indent=2)
            
            # í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ì‹œ ë¡œë“œ
            if load_learned_documents():
                st.sidebar.success("âœ… PDF í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.sidebar.error("âŒ í•™ìŠµ ê²°ê³¼ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
    except Exception as e:
        st.sidebar.error(f"âŒ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™” ë²„íŠ¼
if learning_status["manual"] or learning_status["samples"]:
    if st.sidebar.button("ğŸ—‘ï¸ í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™”", use_container_width=True):
        if reset_learning_data():
            st.sidebar.success("âœ… í•™ìŠµ ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()

# ë¬¸ì„œ íƒ€ì…ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ìƒíƒœ ì´ˆê¸°í™”
if st.session_state.previous_doc_type != doc_type:
    clear_all_state()
    st.session_state.previous_doc_type = doc_type

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” - í‚¤ ìƒì„± ë°©ì‹ ê°œì„ 
draft_key = f"draft_{doc_type.replace(' ', '_')}"
html_key = f"html_{doc_type.replace(' ', '_')}"

# í•„ìš”í•œ ìƒíƒœë§Œ ì´ˆê¸°í™”
state_defaults = {
    draft_key: {},
    html_key: "",
    "clarifying_questions": None,
    "current_keywords": "",
    "file_processing_complete": False,
    "ai_generation_complete": False
}

for key, default_value in state_defaults.items():
    if key not in st.session_state:
        st.session_state[key] = default_value

if openai_available:
    st.title(f"âœï¸ AI {doc_type} ìë™ ìƒì„±")
    col1, col2 = st.columns([3, 1])
    with col1:
        st.success("ğŸ¤– AI ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    with col2:
        if learning_status["manual"] or learning_status["samples"]:
            st.success("ğŸ“š í•™ìŠµ ì™„ë£Œ")
        else:
            st.info("ğŸ“– ë¯¸í•™ìŠµ")
else:
    st.title(f"ğŸ“ {doc_type} í…œí”Œë¦¿")
    st.error("âš ï¸ AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

if not st.session_state.clarifying_questions:
    if openai_available:
        if learning_status["manual"] or learning_status["samples"]:
            # ì‹¤ì œ PDF ì¶”ì¶œ ìƒíƒœ í™•ì¸
            manual_extracted = learned_documents.get('manual', {}).get('source') == 'pdf_extracted'
            samples_extracted = learned_documents.get('samples', {}).get('source') == 'pdf_extracted'
            
            if manual_extracted and samples_extracted:
                st.markdown("ğŸ“š **ì‹¤ì œ PDF ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ê°€ì´ë“œë¼ì¸ì´ ì ìš©ë©ë‹ˆë‹¤.** í•µì‹¬ í‚¤ì›Œë“œë‚˜ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³ , í•„ìš”ì‹œ ì°¸ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.")
            elif manual_extracted or samples_extracted:
                st.markdown("ğŸ“š **ì¼ë¶€ PDF ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ê°€ì´ë“œë¼ì¸ì´ ì ìš©ë©ë‹ˆë‹¤.** í•µì‹¬ í‚¤ì›Œë“œë‚˜ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³ , í•„ìš”ì‹œ ì°¸ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.")
                st.warning("âš ï¸ ì¼ë¶€ PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ì„ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
            else:
                st.markdown("ğŸ“š **ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ì´ ì ìš©ë©ë‹ˆë‹¤.** í•µì‹¬ í‚¤ì›Œë“œë‚˜ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³ , í•„ìš”ì‹œ ì°¸ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.")
                st.warning("âš ï¸ PDF íŒŒì¼ë“¤ì„ ì½ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ì„ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. Streamlit Cloud í™˜ê²½ì—ì„œëŠ” ë¡œì»¬ íŒŒì¼ ì ‘ê·¼ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.markdown("í•µì‹¬ í‚¤ì›Œë“œë‚˜ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³ , í•„ìš”ì‹œ ì°¸ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.")
            st.info("ğŸ’¡ **íŒ**: ì‚¬ì´ë“œë°”ì—ì„œ 'PDF ë¬¸ì„œ í•™ìŠµí•˜ê¸°'ë¥¼ í´ë¦­í•˜ë©´ ë”ìš± ì „ë¬¸ì ì¸ ë¬¸ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.markdown("í˜„ì¬ AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ìë™ ë¬¸ì„œ ìƒì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        with st.expander("API í‚¤ ì„¤ì • ë°©ë²•"):
            st.markdown("""
            1. [OpenAI ì›¹ì‚¬ì´íŠ¸](https://platform.openai.com/)ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”
            2. Streamlit Cloudì˜ ì•± ì„¤ì •ì—ì„œ Secrets ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”
            3. ë‹¤ìŒê³¼ ê°™ì´ API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:
            ```
            OPENAI_API_KEY = "your-api-key-here"
            ```
            4. ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”
            """)
    sub_type = ""
    if doc_type == "í’ˆì˜ì„œ":
        sub_type = st.selectbox("í’ˆì˜ì„œ ì„¸ë¶€ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:", ["ì„ íƒ ì•ˆí•¨", "ë¹„ìš© ì§‘í–‰", "ì‹ ê·œ ì‚¬ì—…/ê³„ì•½", "ì¸ì‚¬/ì •ì±… ë³€ê²½", "ê²°ê³¼/ì‚¬ê±´ ë³´ê³ "])
    keywords = st.text_area("í•µì‹¬ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ì˜ì—…íŒ€ íƒœë¸”ë¦¿ 5ëŒ€ êµ¬ë§¤, ì´ ì˜ˆì‚° 400ë§Œì›, ì—…ë¬´ìš©", height=100, key="keyword_input")
    
    # ì…ë ¥ ê²€ì¦ ë° ì•ˆë‚´
    if keywords:
        word_count = len(keywords.split())
        char_count = len(keywords)
        
        if char_count < 10:
            st.warning("âš ï¸ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìƒì„¸í•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ìµœì†Œ 10ì ì´ìƒ)")
        elif char_count > 1000:
            st.warning("âš ï¸ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.success(f"âœ… ì ì ˆí•œ ê¸¸ì´ì…ë‹ˆë‹¤. (ë‹¨ì–´: {word_count}ê°œ, ë¬¸ì: {char_count}ì)")
    uploaded_files = st.file_uploader("ì°¸ê³  íŒŒì¼ ì—…ë¡œë“œ (ì„ íƒ ì‚¬í•­)", type=['pdf', 'docx', 'pptx', 'xlsx', 'xls', 'txt'], accept_multiple_files=True)
    
    # íŒŒì¼ ì—…ë¡œë“œ ì•ˆë‚´
    if uploaded_files:
        if len(uploaded_files) > 5:
            st.error("âš ï¸ ìµœëŒ€ 5ê°œì˜ íŒŒì¼ë§Œ ì—…ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            uploaded_files = uploaded_files[:5]
        
        total_size = sum(getattr(f, 'size', 0) for f in uploaded_files)
        if total_size > 50 * 1024 * 1024:  # 50MB ì œí•œ
            st.error("âš ï¸ ì „ì²´ íŒŒì¼ í¬ê¸°ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        else:
            st.info(f"íŒŒì¼ {len(uploaded_files)}ê°œ ì—…ë¡œë“œë¨ (ì „ì²´ í¬ê¸°: {total_size/1024/1024:.1f}MB)")
    use_clarifying_questions = st.checkbox("AIì—ê²Œ ì¶”ê°€ ì§ˆë¬¸ì„ ë°›ì•„ ë¬¸ì„œ ì™„ì„±ë„ ë†’ì´ê¸° (ì„ íƒ ì‚¬í•­)")
    ai_button_disabled = not openai_available
    if ai_button_disabled:
        st.warning("âš ï¸ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. Streamlit Secretsì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    if st.button("AI ì´ˆì•ˆ ìƒì„± ì‹œì‘", type="primary", use_container_width=True, disabled=ai_button_disabled):
        # ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬
        validation_errors = []
        
        if not keywords or len(keywords.strip()) < 10:
            validation_errors.append("í•µì‹¬ í‚¤ì›Œë“œë¥¼ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if len(keywords) > 1000:
            validation_errors.append("í‚¤ì›Œë“œëŠ” 1000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if uploaded_files and len(uploaded_files) > 5:
            validation_errors.append("ì°¸ê³  íŒŒì¼ì€ ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        if validation_errors:
            for error in validation_errors:
                st.error(f"âš ï¸ {error}")
        else:
            full_keywords = f"ìœ í˜•: {sub_type} / ë‚´ìš©: {keywords}" if sub_type != "ì„ íƒ ì•ˆí•¨" else keywords
            st.session_state.current_keywords = full_keywords
            file_context = ""
            
            # íŒŒì¼ ì²˜ë¦¬ ì§„í–‰ë¥  í‘œì‹œ
            if uploaded_files:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i, uploaded_file in enumerate(uploaded_files):
                    progress = (i + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                    
                    file_text = read_uploaded_file(uploaded_file)
                    if file_text:
                        file_context += f"--- ì²¨ë¶€ íŒŒì¼: {uploaded_file.name} ---\n{file_text}\n\n"
                
                progress_bar.empty()
                status_text.empty()
                st.success(f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(uploaded_files)}ê°œ íŒŒì¼")
            
            analysis_complete = True
            if use_clarifying_questions:
                with st.spinner("ğŸ¤– AIê°€ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ê°€ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                    analysis = analyze_keywords(full_keywords, doc_type)
                    if analysis and analysis.get("status") == "incomplete":
                        st.session_state.clarifying_questions = analysis.get("questions", [])
                        analysis_complete = False
                        st.info("ğŸ” ë¬¸ì„œ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        st.rerun()
            if analysis_complete:
                # AI ìƒì„± ì§„í–‰ë¥  í‘œì‹œ
                steps = [
                    "ğŸ¤– AIê°€ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                    f"ğŸ“ {doc_type} ì»¨í…ì¸ ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                    "âœ¨ ìµœì¢… ê²€í†  ë° í¬ë§·íŒ… ì¤‘ì…ë‹ˆë‹¤..."
                ]
                progress_bar, status_text = show_progress_with_status(steps)
                
                ai_result = generate_ai_draft(doc_type, full_keywords, file_context)
                
                progress_bar.progress(1.0)
                status_text.text("âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")
                import time
                time.sleep(1)
                
                progress_bar.empty()
                status_text.empty()
                    
                if ai_result:
                    st.session_state[draft_key] = ai_result
                    st.session_state[html_key] = ""
                    st.success("âœ¨ AIê°€ ë¬¸ì„œ ì´ˆì•ˆì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤! ì•„ë˜ì—ì„œ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
                else:
                    st.error("ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
    # ì¶”ê°€ ë„ì›€ë§ ì œê³µ
    with st.expander("íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ ì‘ì„± íŒ"):
        st.markdown("""
        **ì¢‹ì€ í‚¤ì›Œë“œ ì˜ˆì‹œ:**
        - "ë§ˆì¼€íŒ…íŒ€ ë…¸íŠ¸ë¶ 10ëŒ€ êµ¬ë§¤, ì˜ˆì‚° 500ë§Œì›, 2024ë…„ 4ë¶„ê¸° ì§€ê¸‰"
        - "ì‹ ì…ì‚¬ì› ì›ê²©ê·¼ë¬´ ì œë„ ë„ì…, 2025ë…„ 1ì›”ë¶€í„° ì‹œí–‰"
        - "ê³ ê°ì„œë¹„ìŠ¤ ìš´ì˜ì‹œê°„ ì—°ì¥, í‰ì¼ 21ì‹œê¹Œì§€, ì¸ë ¥ ì¦ì› í•„ìš”"
        
        **í”¼í•´ì•¼ í•  í‚¤ì›Œë“œ:**
        - ë„ˆë¬´ ê°„ë‹¨: "ë…¸íŠ¸ë¶ êµ¬ë§¤"
        - ë„ˆë¬´ ëª¨í˜¸: "ì—¬ëŸ¬ ê°€ì§€ ì‚¬ë¬´ìš©í’ˆ êµ¬ë§¤ ê´€ë ¨"
        - ë°°ê²½ ì„¤ëª… ì—†ì´: "ì˜ˆì‚° ìŠ¹ì¸ ìš”ì²­"
        """)
else:
    st.subheader("AIì˜ ì¶”ê°€ ì§ˆë¬¸ ğŸ™‹â€â™‚ï¸")
    st.info("ë¬¸ì„œì˜ ì™„ì„±ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    answers = {}
    for i, q in enumerate(st.session_state.clarifying_questions):
        answer = st.text_input(q, key=f"q_{i}")
        answers[q] = answer
        
        # ì§ˆë¬¸ë³„ ì…ë ¥ ê²€ì¦
        if answer and len(answer.strip()) < 3:
            st.warning(f"âš ï¸ ì§ˆë¬¸ {i+1}: ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìƒì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.")
        elif answer and len(answer) > 500:
            st.warning(f"âš ï¸ ì§ˆë¬¸ {i+1}: ë„ˆë¬´ ê¹ë‹ˆë‹¤. 500ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    if st.button("ë‹µë³€ ì œì¶œí•˜ê³  ë¬¸ì„œ ìƒì„±í•˜ê¸°", type="primary", use_container_width=True, disabled=not openai_available):
        # ë‹µë³€ ìœ íš¨ì„± ê²€ì‚¬
        answered_questions = [q for q, a in answers.items() if a.strip()]
        if len(answered_questions) == 0:
            st.warning("âš ï¸ ì ì–´ë„ í•˜ë‚˜ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.")
        else:
            combined_info = st.session_state.current_keywords + "\n[ì¶”ê°€ ì •ë³´]\n"
            for q, a in answers.items():
                if a: combined_info += f"- {q}: {a}\n"
            
            # ì§„í–‰ë¥  í‘œì‹œ
            steps = [
                "ğŸ” ì¶”ê°€ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                f"ğŸ“ í–¥ìƒëœ {doc_type}ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "âœ¨ ìµœì¢… ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."
            ]
            progress_bar, status_text = show_progress_with_status(steps)
            
            ai_result = generate_ai_draft(doc_type, combined_info)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… ê°œì„ ëœ ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")
            import time
            time.sleep(1)
            
            progress_bar.empty()
            status_text.empty()
            
            if ai_result:
                st.session_state[draft_key] = ai_result
                st.session_state.clarifying_questions = None
                st.session_state.current_keywords = ""
                st.session_state[html_key] = ""
                st.success("âœ¨ ì¶”ê°€ ì •ë³´ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

st.divider()
draft = st.session_state.get(draft_key, {})

if draft:
    preview_button = False; signature_data = {}
    st.markdown("---")
    st.subheader("ğŸ“„ AI ìƒì„± ì´ˆì•ˆ ê²€í†  ë° ìˆ˜ì •")
    if doc_type == 'í’ˆì˜ì„œ':
        p_data = draft
        title_input = st.text_input("ì œëª©", value=p_data.get("title", ""), help="ê²°ì¬ìê°€ ì œëª©ë§Œ ë³´ê³ ë„ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.")
        if title_input and len(title_input.strip()) < 5:
            st.warning("âš ï¸ ì œëª©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ë“œë¦½ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        elif title_input and len(title_input) > 100:
            st.warning("âš ï¸ ì œëª©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 100ì ì´í•˜ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        p_data["title"] = title_input
        
        purpose_input = st.text_area("ëª©ì  ë° ê°œìš”", value=p_data.get("purpose", ""), height=100, help="ì´ í’ˆì˜ë¥¼ ì˜¬ë¦¬ëŠ” ì´ìœ ì™€ ëª©í‘œë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ê¸°ìˆ í•©ë‹ˆë‹¤. (Why)")
        if purpose_input and len(purpose_input.strip()) < 20:
            st.warning("âš ï¸ ëª©ì ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        p_data["purpose"] = purpose_input
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© í¸ì§‘
        st.markdown("**ìƒì„¸ ì„¤ëª… (í…ìŠ¤íŠ¸)**")
        p_data["body_edited"] = st.text_area("ë°°ê²½ ë° ì„¤ëª…", value=p_data.get("body", ""), height=150, help="ë°°ê²½, í•„ìš”ì„±, ì¶”ì§„ ë°©ë²• ë“±ì„ í…ìŠ¤íŠ¸ë¡œ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.")
        
        # í‘œ ë°ì´í„° í¸ì§‘
        st.markdown("**ìƒì„¸ ë‚´ì—­ (í‘œ)**")
        if "items" in p_data and p_data["items"] and len(p_data["items"]) > 0:
            # AIê°€ ìƒì„±í•œ í‘œê°€ ìˆëŠ” ê²½ìš°
            p_data["df"] = pd.DataFrame(p_data.get("items", []))
            p_data["df_edited"] = st.data_editor(p_data["df"], num_rows="dynamic", help="êµ¬ì²´ì ì¸ í•­ëª©, ìˆ˜ëŸ‰, ê¸ˆì•¡ ë“±ì„ í‘œë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")
        else:
            # í‘œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ì œê³µ
            default_items = [
                {"í•­ëª©": "ì˜ˆì‹œ í•­ëª©", "ìˆ˜ëŸ‰": "1", "ë‹¨ê°€": "100,000", "ê¸ˆì•¡": "100,000", "ë¹„ê³ ": "ì„¤ëª…"}
            ]
            p_data["df_edited"] = st.data_editor(pd.DataFrame(default_items), num_rows="dynamic", help="êµ¬ì²´ì ì¸ í•­ëª©, ìˆ˜ëŸ‰, ê¸ˆì•¡ ë“±ì„ í‘œë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")
        
        p_data["remarks"] = st.text_area("ë¹„ê³ ", value=p_data.get("remarks", ""), height=150, help="ì˜ˆìƒ ë¹„ìš©(How much), ì†Œìš” ê¸°ê°„(How long), ê¸°ëŒ€ íš¨ê³¼ ë“± ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´ë¥¼ ê¸°ì…í•©ë‹ˆë‹¤.")
        
        # í’ˆì˜ì„œ ìœ íš¨ì„± ê²€ì‚¬
        validation_errors = validate_document_fields(doc_type, p_data)
        
        if validation_errors:
            for error in validation_errors:
                st.error(f"âš ï¸ {error}")
            preview_button = st.button("ë¯¸ë¦¬ë³´ê¸° ìƒì„±", use_container_width=True, disabled=True)
        else:
            preview_button = st.button("ë¯¸ë¦¬ë³´ê¸° ìƒì„±", use_container_width=True)
    elif doc_type == 'ê³µì§€ë¬¸':
        g_data = draft
        g_data["title"] = st.text_input("ì œëª©", value=g_data.get("title", ""), help="ê³µì§€ì˜ ë‚´ìš©ì„ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.")
        g_data["target"] = st.text_input("ëŒ€ìƒ", value=g_data.get("target", ""), help="ê³µì§€ì˜ ì ìš© ë²”ìœ„ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤. (ì˜ˆ: ì „ ì§ì›)")
        g_data["summary"] = st.text_area("í•µì‹¬ ìš”ì•½", value=g_data.get("summary", ""), height=100, help="ë³¸ë¬¸ ìƒë‹¨ì— í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ê³µì§€ì˜ í•µì‹¬ì„ ìš”ì•½í•©ë‹ˆë‹¤.")
        # ìƒì„¸ ë‚´ìš©ì´ JSON ê°ì²´ í˜•íƒœì¸ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        details_value = g_data.get("details", "")
        if isinstance(details_value, dict):
            formatted_details = ""
            for key, value in details_value.items():
                if key.strip() in ['1.', '2.', '3.', '4.', '5.']:
                    formatted_details += f"{key} {value}\n"
                elif key.strip().endswith(')') and key.strip().replace(')', '').strip().isdigit():
                    formatted_details += f"  {key} {value}\n"
                elif key.strip().startswith('(') and key.strip().endswith(')'):
                    formatted_details += f"    {key} {value}\n"
                else:
                    formatted_details += f"{key} {value}\n"
            details_value = formatted_details
        
        g_data["details"] = st.text_area("ìƒì„¸ ë‚´ìš©", value=details_value, height=200, help="5W1H ì›ì¹™ì— ë”°ë¼ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë²ˆí˜¸ ë§¤ê¸°ê¸°: 1. â†’ 1) â†’ (1)")
        g_data["contact"] = st.text_input("ë¬¸ì˜ì²˜", value=g_data.get("contact", ""), help="ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•  ë‹´ë‹¹ì ì •ë³´ì…ë‹ˆë‹¤.")
        preview_button = st.button("ë¯¸ë¦¬ë³´ê¸° ìƒì„±", use_container_width=True)
    elif doc_type == 'ê³µë¬¸':
        gm_data = draft
        gm_data["sender_org"] = st.text_input("ë°œì‹  ê¸°ê´€ëª…", value=gm_data.get("sender_org", ""))
        gm_data["receiver"] = st.text_input("ìˆ˜ì‹ ", value=gm_data.get("receiver", ""))
        gm_data["cc"] = st.text_input("ì°¸ì¡°", value=gm_data.get("cc", ""))
        gm_data["title"] = st.text_input("ì œëª©", value=gm_data.get("title", ""))
        gm_data["body"] = st.text_area("ë‚´ìš©", value=gm_data.get("body", ""), height=250)
        gm_data["sender_name"] = st.text_input("ë°œì‹  ëª…ì˜", value=gm_data.get("sender_name", ""))
        preview_button = st.button("ë¯¸ë¦¬ë³´ê¸° ìƒì„±", use_container_width=True)
    elif doc_type == 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼':
        e_data = draft
        st.subheader("ë°›ëŠ” ì‚¬ëŒ ì •ë³´")
        signature_data["recipient_name"] = st.text_input("ë°›ëŠ” ì‚¬ëŒ ì´ë¦„", value=e_data.get("recipient_name", ""))
        signature_data["recipient_title"] = st.text_input("ë°›ëŠ” ì‚¬ëŒ ì§ì±…", value=e_data.get("recipient_title", ""))
        e_data["cc"] = st.text_input("ì°¸ì¡° (CC)", value=e_data.get("cc", ""))
        st.subheader("ë©”ì¼ ë‚´ìš©")
        e_data["subject"] = st.text_input("ì œëª©", value=e_data.get("subject", ""))
        e_data["body"] = st.text_area("ë³¸ë¡ ", value=e_data.get("body", ""), height=200)
        e_data["closing"] = st.text_area("ê²°ë¡ ", value=e_data.get("closing", ""), height=100)
        with st.expander("ë‚´ ì„œëª… ì •ë³´ ì…ë ¥/ìˆ˜ì •"):
            signature_data["signature_name"] = st.text_input("ì´ë¦„", value="í™ê¸¸ë™")
            signature_data["signature_title"] = st.text_input("ì§ì±…", value="ëŒ€ë¦¬")
            signature_data["signature_team"] = st.text_input("ë¶€ì„œ/íŒ€", value="ë§ˆì¼€íŒ…íŒ€")
            signature_data["signature_phone"] = st.text_input("ì—°ë½ì²˜", value="010-1234-5678")
        preview_button = st.button("ì´ë©”ì¼ ë³¸ë¬¸ ìƒì„±", use_container_width=True)
    
    if preview_button:
        if doc_type == 'í’ˆì˜ì„œ':
            # ì œëª©, ëª©ì , ë¹„ê³  ì—…ë°ì´íŠ¸
            draft['title'] = p_data["title"]
            draft['purpose'] = p_data["purpose"] 
            draft['remarks'] = p_data["remarks"]
            
            # í…ìŠ¤íŠ¸ ë‚´ìš© í•­ìƒ í¬í•¨
            draft['body'] = p_data["body_edited"]
            
            # í‘œ ë°ì´í„° í•­ìƒ í¬í•¨ (ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
            if not p_data["df_edited"].empty:
                # ë¹ˆ í–‰ ì œê±°
                filtered_df = p_data["df_edited"].dropna(how='all')
                if not filtered_df.empty:
                    draft['items'] = filtered_df.to_dict('records')
                else:
                    draft['items'] = []
            else:
                draft['items'] = []
            
            # í…œí”Œë¦¿ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = { 
                "title": draft["title"], 
                "purpose": text_to_html(draft["purpose"]), 
                "remarks": text_to_html(draft["remarks"]), 
                "generation_date": datetime.now().strftime('%Y-%m-%d') 
            }
            
            # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ê°€
            if draft.get("body"):
                context["body"] = text_to_html(draft["body"])
            
            # í‘œ ë°ì´í„° ì¶”ê°€
            if draft.get("items"):
                context["table_headers"] = list(p_data["df_edited"].columns)
                context["items"] = draft["items"]
            
            template = load_template('pumui_template_final.html')
            st.session_state[html_key] = generate_html(template, context)
        elif doc_type == 'ê³µì§€ë¬¸':
            draft = g_data
            context = { "title": draft["title"], "target": draft["target"], "summary": text_to_html(draft["summary"]), "details": text_to_html(draft["details"]), "contact": draft["contact"], "generation_date": datetime.now().strftime('%Y. %m. %d.') }
            template = load_template('gongji_template.html')
            st.session_state[html_key] = generate_html(template, context)
        elif doc_type == 'ê³µë¬¸':
            draft = gm_data
            context = { "sender_org": draft["sender_org"], "receiver": draft["receiver"], "cc": draft["cc"], "title": draft["title"], "body": text_to_html(draft["body"]), "sender_name": draft["sender_name"], "generation_date": datetime.now().strftime('%Y. %m. %d.') }
            template = load_template('gongmun_template.html')
            st.session_state[html_key] = generate_html(template, context)
        elif doc_type == 'ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼':
            draft = {**e_data, **signature_data}
            context = draft.copy()
            context["signature_company"] = "ì£¼ì‹íšŒì‚¬ ëª¬ì‰˜ì½”ë¦¬ì•„"
            template = load_template('email_template_v2.html')
            st.session_state[html_key] = generate_html(template, context)

if st.session_state.get(html_key):
    st.divider()
    st.subheader("ğŸ“„ ìµœì¢… ë¯¸ë¦¬ë³´ê¸°")
    components.html(st.session_state[html_key], height=600, scrolling=True)
    if doc_type == "ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼":
        st.subheader("ğŸ“‹ ë³µì‚¬í•  HTML ì½”ë“œ")
        st.code(st.session_state[html_key], language='html')
    else:
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            pdf_output = generate_pdf(st.session_state[html_key])
            title_for_file = draft.get("title", "document")
            st.download_button(label="ğŸ“¥ PDF íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=pdf_output, file_name=f"{title_for_file}.pdf", mime="application/pdf", use_container_width=True)
        with col2:
            docx_output = generate_docx(draft, doc_type, signature_data)
            st.download_button(label="ğŸ“„ Word íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=docx_output, file_name=f"{title_for_file}.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
